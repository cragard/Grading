{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook cleans .txt data for students performance on exams for BIO1111 and exports a csv which can be analyzed in an R script.\n",
    "#### Author: Christopher Agard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,glob\n",
    "\n",
    "def cleanSoarExam (data, examNum, fileType='flat',\n",
    "                   colSpec = [(0,9),(10,21),(22,28),(29,30),(30,32),(32,34),(34,36),(36,38),(39,41),(41,68)],\n",
    "                   soarSessions=[]):\n",
    "\n",
    "    if fileType != 'flat':\n",
    "        print(\"\\n{} fileType is not currently supported.\".format(fileType))\n",
    "    else:\n",
    "        try:\n",
    "            df=pd.read_fwf(data,colSpec,names=['tuid','last','first','middle','unnamed1','unnamed2','unnamed3','soar','ncorrect','item'])\n",
    "        except:\n",
    "            \"print(\\nCould not find file {} or {} was not acceptable value for colSpec)\".format(data,colSpec)\n",
    "        #try:\n",
    "        #    df.columns = ['tuid','last','first','middle','unnamed1','unnamed2','unnamed3','soar','ncorrect','item']\n",
    "        #except:\n",
    "        #    print(\"\\nColumn number != 10.\\n{}\".format(len(df.columns)))\n",
    "        try:\n",
    "            df['examNumber']=examNum\n",
    "            numbers=pd.Series(list(range(28))).astype(str)\n",
    "            itemNames= 'item_'+ numbers[1:]\n",
    "            itemData=df.item.apply(lambda i: pd.Series(list(i)))\n",
    "            itemData.columns=itemNames\n",
    "            df=df.merge(itemData,'outer',left_index=True,right_index=True).drop('item',axis=1)\n",
    "        except:\n",
    "            print(\"\\nUnhandled exception encountered.\")\n",
    "        if soarSessions ==np.nan:\n",
    "            df.loc['soarType']='other'\n",
    "        else:\n",
    "            df.loc[df.soar.isin(soarSessions),'soarType']='mine'\n",
    "            df.loc[~df.soar.isin(soarSessions),'soarType']='other'\n",
    "            df.loc[df.tuid=='NNNNNNNNN','soarType']='key'\n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here we need to write a function to determine how many students get each item wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "def nwrong (x,key):\n",
    "    \"\"\"\n",
    "    :param x: pd.Series\n",
    "    :param key: ~None\n",
    "    Takes a pandas series and a specified value and returns the number of values \n",
    "    in the series which do not match the specified value.\"\"\"\n",
    "    assert isinstance(x, pd.Series)\n",
    "    x = x.astype(str)\n",
    "    key = str(key)\n",
    "    return x[x!=key].count()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(string.ascii_lowercase)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,glob\n",
    "\n",
    "pd.options.display.max_columns=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Exam Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define paths for getting exam data and outputting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "homesource = 'S:/Chris/Temple/Biol1111/Fall 2018/Raw Data/Exam 1'\n",
    "homeoutputFolder = 'S:/Chris/Temple/Biol1111/Fall 2018/Results/Exam 1'\n",
    "worksource = 'C:/Users/tuh27554/Documents/BIOL1111/Fall 2018/Raw Data/Exam 1'\n",
    "workoutputFolder = 'C:/Users/tuh27554/Documents/BIOL1111/Fall 2018/Results/Exam 1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get a list of source data files. For this notebook we will use the \\*.txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['V1Raw.txt', 'V2Raw.txt']\n"
     ]
    }
   ],
   "source": [
    "os.chdir(worksource)\n",
    "files = glob.glob('*.txt')\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " And now we read in and clean those data using the *cleanSoarExam* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 1 of the exam has 123 students.\n",
      "Version 2 of the exam has 122 students.\n"
     ]
    }
   ],
   "source": [
    "df1 = cleanSoarExam(files[0],examNum=1,soarSessions=[81])\n",
    "print('Version 1 of the exam has {} students.'.format(df1.shape[0]-1))\n",
    "df2 = cleanSoarExam(files[1],examNum=1,soarSessions=[81])\n",
    "print('Version 2 of the exam has {} students.'.format(df2.shape[0]-1))\n",
    "os.chdir(workoutputFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df1.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df2.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Exam Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining the most problematic items for the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to identify the item columns over which to apply *nwrong*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "itemcols1 = df1.columns[df1.columns.str.contains('item_')]\n",
    "itemcols2 = df2.columns[df2.columns.str.contains('item_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply the function to determine the number of students who answered incorrectly for version 1 and version 2 separately. We will only print one of these here for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_1     2\n",
       "item_2     4\n",
       "item_3     3\n",
       "item_4     3\n",
       "item_5     3\n",
       "item_6     4\n",
       "item_7     3\n",
       "item_8     4\n",
       "item_9     8\n",
       "item_10    3\n",
       "item_11    3\n",
       "item_12    4\n",
       "item_13    4\n",
       "item_14    7\n",
       "item_15    4\n",
       "item_16    4\n",
       "item_17    7\n",
       "item_18    2\n",
       "item_19    0\n",
       "item_20    8\n",
       "item_21    8\n",
       "item_22    1\n",
       "item_23    2\n",
       "item_24    0\n",
       "item_25    4\n",
       "item_26    6\n",
       "item_27    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1wrong = df1.loc[df1.soarType.isin(['mine','key']),itemcols1].apply(lambda x: nwrong(x=x[1:],key=x[0]))\n",
    "v2wrong = df2.loc[df2.soarType.isin(['mine','key']),itemcols2].apply(lambda x: nwrong(x=x[1:],key=x[0]))\n",
    "v2wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding these lists together we get the total number wrong on each item.  If we sort the resulting series in descending order, we will have the guide we need to determine the order for discussing the items in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_27    21\n",
       "item_21    20\n",
       "item_14    15\n",
       "item_9     13\n",
       "item_17    12\n",
       "item_15    10\n",
       "item_20    10\n",
       "item_26    10\n",
       "item_3      9\n",
       "item_13     9\n",
       "item_8      8\n",
       "item_11     8\n",
       "item_6      8\n",
       "item_16     7\n",
       "item_23     6\n",
       "item_12     6\n",
       "item_5      6\n",
       "item_7      6\n",
       "item_10     5\n",
       "item_4      4\n",
       "item_2      4\n",
       "item_1      4\n",
       "item_18     4\n",
       "item_25     4\n",
       "item_22     2\n",
       "item_24     1\n",
       "item_19     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalwrong = v1wrong + v2wrong\n",
    "orderedwrong = totalwrong.sort_values(ascending=False)\n",
    "orderedwrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also print the letters for the correct answers for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_1     B\n",
       "item_2     D\n",
       "item_3     B\n",
       "item_4     B\n",
       "item_5     C\n",
       "item_6     A\n",
       "item_7     D\n",
       "item_8     B\n",
       "item_9     C\n",
       "item_10    B\n",
       "item_11    C\n",
       "item_12    D\n",
       "item_13    D\n",
       "item_14    C\n",
       "item_15    A\n",
       "item_16    C\n",
       "item_17    A\n",
       "item_18    A\n",
       "item_19    A\n",
       "item_20    C\n",
       "item_21    B\n",
       "item_22    C\n",
       "item_23    B\n",
       "item_24    A\n",
       "item_25    C\n",
       "item_26    A\n",
       "item_27    D\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "v1keys = df1.loc[df1.soarType=='key',itemcols1].apply(lambda x: list(string.ascii_uppercase)[int(x)-1])\n",
    "v1keys\n",
    "# v2wrong = df2.loc[df2.soarType.isin(['mine','key']),itemcols2].apply(lambda x: nwrong(x=x[1:],key=x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here we need to write a function to determine how many students get each item wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_1     B\n",
       "item_2     D\n",
       "item_3     B\n",
       "item_4     B\n",
       "item_5     C\n",
       "item_6     A\n",
       "item_7     D\n",
       "item_8     B\n",
       "item_9     C\n",
       "item_10    B\n",
       "item_11    C\n",
       "item_12    D\n",
       "item_13    D\n",
       "item_14    C\n",
       "item_15    A\n",
       "item_16    C\n",
       "item_17    A\n",
       "item_18    A\n",
       "item_19    A\n",
       "item_20    C\n",
       "item_21    B\n",
       "item_22    C\n",
       "item_23    B\n",
       "item_24    A\n",
       "item_25    C\n",
       "item_26    A\n",
       "item_27    D\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2keys = df1.loc[df1.soarType=='key',itemcols2].apply(lambda x: list(string.ascii_uppercase)[int(x)-1])\n",
    "v2keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating students performace "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at scores by section.  For this we can rename *unnamed1* to *version* to keep track of the versions and append the 2 dfs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247, 38)\n"
     ]
    }
   ],
   "source": [
    "df = df1.append(df2)\n",
    "print(df.shape)\n",
    "df.to_csv('merged exam 1 results.csv')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop the \"key\" data and store as a separate variable,*maxscore*, the maximum possible value for ncorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxscore:27\n"
     ]
    }
   ],
   "source": [
    "maxscore = df.ncorrect.max()\n",
    "df = df.loc[df.soarType!='key',:]\n",
    "print('maxscore:{}'.format(maxscore))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this *df* for the rest of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soar</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71.0</th>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.517241</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75.0</th>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.848485</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83.0</th>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>19.5</td>\n",
       "      <td>18.807692</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84.0</th>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>19.5</td>\n",
       "      <td>18.964286</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81.0</th>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.161290</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87.0</th>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72.0</th>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "      <td>20.5</td>\n",
       "      <td>19.218750</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73.0</th>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.718750</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      min  max  median       mean  count\n",
       "soar                                    \n",
       "21.0   12   12    12.0  12.000000      1\n",
       "6.0    15   15    15.0  15.000000      1\n",
       "2.0    19   19    19.0  19.000000      1\n",
       "71.0    7   26    19.0  18.517241     29\n",
       "75.0    9   24    19.0  17.848485     33\n",
       "83.0   12   26    19.5  18.807692     26\n",
       "84.0   11   24    19.5  18.964286     28\n",
       "81.0   12   26    20.0  20.161290     31\n",
       "87.0   12   25    20.0  20.000000     27\n",
       "72.0    9   26    20.5  19.218750     32\n",
       "73.0   11   27    21.0  20.718750     32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = df.groupby(['soar']).ncorrect.agg(['min','max','median','mean','count']).sort_values('median')\n",
    "scores.to_csv('Exam1Score breakdown.csv')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soar\n",
      "2.0     19.00\n",
      "6.0     15.00\n",
      "21.0    12.00\n",
      "71.0    22.00\n",
      "72.0    22.25\n",
      "73.0    23.00\n",
      "75.0    20.00\n",
      "81.0    22.50\n",
      "83.0    21.75\n",
      "84.0    21.50\n",
      "87.0    22.50\n",
      "Name: ncorrect, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby('soar').ncorrect.quantile(.75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the distribution of individuals who scored above the 75-percentile in their class.  This gives us an idea of how distributed the high scores are in each section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soar</th>\n",
       "      <th>nAbove75p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>81.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>83.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>87.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    soar  nAbove75p\n",
       "0    2.0          0\n",
       "1    6.0          0\n",
       "2   21.0          0\n",
       "3   71.0          6\n",
       "4   72.0          8\n",
       "5   73.0          6\n",
       "6   75.0          7\n",
       "7   81.0          8\n",
       "8   83.0          7\n",
       "9   84.0          7\n",
       "10  87.0          7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highAchieverslocal = df.groupby('soar').ncorrect.apply(lambda x: x.loc[x>x.quantile(.75)].count()).reset_index()\\\n",
    ".rename(columns = {'ncorrect':'nAbove75p'})\n",
    "highAchieverslocal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the distribution of individuals who scored above the 75-percentile across the entire class.  This gives us an idea of how distributed the high scores are across sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall all median and 75 percentile were 20.0 and 22.0, respectively.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>soar</th>\n",
       "      <th>nAbove75p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>83.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>87.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   soar  nAbove75p\n",
       "0  71.0          6\n",
       "1  72.0          8\n",
       "2  73.0         11\n",
       "3  75.0          4\n",
       "4  81.0          8\n",
       "5  83.0          4\n",
       "6  84.0          7\n",
       "7  87.0          7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highAchieversGlobal = df.loc[df.ncorrect>df.ncorrect.quantile(.75)]\\\n",
    ".groupby('soar').ncorrect.count().reset_index()\\\n",
    ".rename(columns = {'ncorrect':'nAbove75p'})\n",
    "print('The overall all median and 75 percentile were {} and {}, \\\n",
    "respectively.'.format(df.ncorrect.median(),df.ncorrect.quantile(.75)))\n",
    "highAchieversGlobal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
